{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaRank Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_offsets(arr):\n",
    "    \"\"\"Return a sequence of start/end offsets for the value subgroups in the input\"\"\"\n",
    "    d = np.ones(arr.size, dtype=int)\n",
    "    d[1:] = (arr[:-1] != arr[1:]).astype(int)\n",
    "    idx = np.where(np.append(d, 1))[0]\n",
    "    return zip(idx, idx[1:])\n",
    "\n",
    "\n",
    "class Scorer(object):\n",
    "    def __init__(self, score_func, **kwargs):\n",
    "        self.score_func = score_func\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.score_func(*args, **self.kwargs)\n",
    "\n",
    "\n",
    "# DCG/nDCG (Normalized Discounted Cumulative Gain)\n",
    "# https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "\n",
    "def _burges_dcg(y_true, y_pred, k=None):\n",
    "    # order = np.argsort(y_pred)[::-1]\n",
    "    order = np.argsort(-y_pred)\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gain = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(gain)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "def _dcg_score(y_true, y_pred, qid, k=None, dcg_func=None):\n",
    "    assert dcg_func is not None\n",
    "    y_true = np.maximum(y_true, 0)\n",
    "    return np.array([dcg_func(y_true[a:b], y_pred[a:b], k=k) for a, b in group_offsets(qid)])\n",
    "\n",
    "def _ndcg_score(y_true, y_pred, qid, k=None, dcg_func=None):\n",
    "    assert dcg_func is not None\n",
    "    y_true = np.maximum(y_true, 0)\n",
    "    dcg = _dcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
    "    idcg = np.array([dcg_func(np.sort(y_true[a:b]), np.arange(0, b - a), k=k)\n",
    "                     for a, b in group_offsets(qid)])\n",
    "    assert (dcg <= idcg).all()\n",
    "    idcg[idcg == 0] = 1\n",
    "    return dcg / idcg\n",
    "\n",
    "def ndcg_score(y_true, y_pred, qid, k=None):\n",
    "    dcg_func = _burges_dcg \n",
    "    return _ndcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
    "\n",
    "class NDCGScorer(Scorer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NDCGScorer, self).__init__(ndcg_score, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaRank Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaRank(sklearn.base.BaseEstimator):\n",
    "    \"\"\"AdaRank algorithm\"\"\"\n",
    "\n",
    "    def __init__(self, max_iter=500, tol=0.0001, estop=1, verbose=False, scorer=None):\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.estop = estop\n",
    "        self.verbose = verbose\n",
    "        self.scorer = scorer\n",
    "\n",
    "    def fit(self, X, y, qid, X_valid=None, y_valid=None, qid_valid=None):\n",
    "        \"\"\"Fit a model to the data\"\"\"\n",
    "        X, y = check_X_y(X, y, 'csr')\n",
    "        \n",
    "        # if is already array dont convert\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        if X_valid is None:\n",
    "            X_valid, y_valid, qid_valid = X, y, qid\n",
    "        else:\n",
    "            X_valid, y_valid = check_X_y(X_valid, y_valid, 'csr')\n",
    "            X_valid = X_valid.toarray()\n",
    "\n",
    "        n_queries = np.unique(qid).shape[0]\n",
    "        weights = np.ones(n_queries, dtype=np.float64) / n_queries\n",
    "        weak_rankers = []\n",
    "        coef = np.zeros(X.shape[1])\n",
    "\n",
    "        # use nDCG@10 as the default scorer\n",
    "        if self.scorer is None:\n",
    "            self.scorer = NDCGScorer(k=10)\n",
    "\n",
    "        # precompute performance measurements for all weak rankers\n",
    "        weak_ranker_score = []\n",
    "        for j in range(X.shape[1]):\n",
    "            pred = X[:, j].ravel()\n",
    "            weak_ranker_score.append(self.scorer(y, pred, qid))\n",
    "            \n",
    "        best_perf_train = -np.inf\n",
    "        best_perf_valid = -np.inf\n",
    "        used_fids = []\n",
    "        estop = None\n",
    "\n",
    "        self.n_iter = 0\n",
    "        while self.n_iter < self.max_iter:\n",
    "            self.n_iter += 1\n",
    "\n",
    "            best_weighted_average = -np.inf\n",
    "            best_weak_ranker = None\n",
    "            for fid, score in enumerate(weak_ranker_score):\n",
    "                if fid in used_fids:\n",
    "                    continue\n",
    "                weighted_average = np.dot(weights, score)\n",
    "                if weighted_average > best_weighted_average:\n",
    "                    best_weak_ranker = {'fid': fid, 'score': score}\n",
    "                    best_weighted_average = weighted_average\n",
    "\n",
    "            # stop when all the weaker rankers are out\n",
    "            if best_weak_ranker is None:\n",
    "                break\n",
    "\n",
    "            h = best_weak_ranker\n",
    "            h['alpha'] = 0.5 * (math.log(np.dot(weights, 1 + h['score']) /\n",
    "                                         np.dot(weights, 1 - h['score'])))\n",
    "            weak_rankers.append(h)\n",
    "\n",
    "            # update the ranker\n",
    "            coef[h['fid']] += h['alpha']\n",
    "\n",
    "            # if len(used_fids) > 5:\n",
    "            #     used_fids.pop(0)\n",
    "            # used_fids.append(h['fid'])\n",
    "\n",
    "            # score both training and validation data\n",
    "            score_train = self.scorer(y, np.dot(X, coef), qid)\n",
    "            perf_train = score_train.mean()\n",
    "\n",
    "            perf_valid = perf_train\n",
    "            if X_valid is not X:\n",
    "                perf_valid = self.scorer(y_valid, np.dot(X_valid, coef), qid_valid).mean()\n",
    "\n",
    "            if self.verbose:\n",
    "                print('{n_iter}\\t{alpha}\\t{fid}\\t{score}\\ttrain {train:.4f}\\tvalid {valid:.4f}'.\n",
    "                      format(n_iter=self.n_iter, alpha=h['alpha'], fid=h['fid'],\n",
    "                             score=h['score'][:5], train=perf_train, valid=perf_valid),\n",
    "                      file=sys.stderr)\n",
    "\n",
    "            # update the best validation scores\n",
    "            if perf_valid > best_perf_valid + self.tol:\n",
    "                estop = 0\n",
    "                best_perf_valid = perf_valid\n",
    "                self.coef_ = coef.copy()\n",
    "            else:\n",
    "                estop += 1\n",
    "\n",
    "            # update the best training score\n",
    "            if perf_train > best_perf_train + self.tol:\n",
    "                best_perf_train = perf_train\n",
    "            else:\n",
    "                # stop if scores on both sets fail to improve\n",
    "                if estop >= self.estop:\n",
    "                    break\n",
    "\n",
    "            # update weights\n",
    "            new_weights = np.exp(-score_train)\n",
    "            weights = new_weights / new_weights.sum()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, qid):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "        return np.dot(X, self.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on MQ2007 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, qid = load_svmlight_file(\"datasets/mq2007/train.txt\", query_id=True)\n",
    "    \n",
    "X_test, y_test, qid_test = load_svmlight_file(\"datasets/mq2007/test.txt\", query_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@1\t0.40773809523809523\n",
      "nDCG@2\t0.39950776144698336\n",
      "nDCG@3\t0.4079126410276921\n",
      "nDCG@4\t0.4069481096852681\n",
      "nDCG@5\t0.41673937966570745\n",
      "nDCG@10\t0.4502928537269599\n",
      "nDCG@20\t0.5065914762962426\n"
     ]
    }
   ],
   "source": [
    "# hyper params\n",
    "k = 10\n",
    "max_iter = 100\n",
    "patience = 20\n",
    "\n",
    "model = AdaRank(max_iter=max_iter,\n",
    "                    estop=patience,\n",
    "                    verbose=False,\n",
    "                    scorer=NDCGScorer(k=k))\n",
    "\n",
    "model.fit(X, y, qid)\n",
    "\n",
    "predictions = model.predict(X_test, qid_test)\n",
    "for k in (1, 2, 3, 4, 5, 10, 20):\n",
    "        score = NDCGScorer(k=k)(y_test, predictions, qid_test).mean()\n",
    "        print('nDCG@{}\\t{}'.format(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on LOINC original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_loinc(path ='datasets/loinc_features.xlsx', test_split=0.10):\n",
    "    # read excel file\n",
    "    df_loinc_q0 = pd.read_excel(path, sheet_name=0)\n",
    "    df_loinc_q1 = pd.read_excel(path, sheet_name=1)\n",
    "    df_loinc_q2 = pd.read_excel(path, sheet_name=2)\n",
    "\n",
    "    y0 = df_loinc_q0[\"RANK\"].values\n",
    "    y1 = df_loinc_q0[\"RANK\"].values\n",
    "    y2 = df_loinc_q0[\"RANK\"].values\n",
    "    #concat y   \n",
    "    y = np.concatenate((y0, y1, y2), axis=0)\n",
    "\n",
    "    features_names = [\"IDF\", \"BM25\", \"COISINE\",\t\"JACCARD\"] \n",
    "    df_loinc_q0 = df_loinc_q0[features_names].values\n",
    "    df_loinc_q1 = df_loinc_q1[features_names].values\n",
    "    df_loinc_q2 = df_loinc_q2[features_names].values\n",
    "    # concat features\n",
    "    X = np.concatenate((df_loinc_q0, df_loinc_q1, df_loinc_q2), axis=0)\n",
    "\n",
    "    # prepare qid\n",
    "    qid0 = np.full(len(df_loinc_q0), 0)\n",
    "    qid1 = np.full(len(df_loinc_q1), 1)\n",
    "    qid2 = np.full(len(df_loinc_q2), 2)\n",
    "    # concat qids\n",
    "    qid = np.concatenate((qid0, qid1, qid2), axis=0)\n",
    "    \n",
    "    # Get the unique 'qid' values\n",
    "    unique_qid = np.unique(qid)\n",
    "\n",
    "    # Initialize empty arrays for the training and testing sets\n",
    "    X_train, X_test, y_train, y_test, qid_train, qid_test = [], [], [], [], [], []\n",
    "\n",
    "    # Split the data based on 'qid'\n",
    "    test_size = test_split # Adjust as needed\n",
    "    for q in unique_qid:\n",
    "        mask = qid == q  # Create a mask for the current 'qid'\n",
    "        X_q = X[mask]\n",
    "        y_q = y[mask]\n",
    "        qid_q = qid[mask]\n",
    "\n",
    "        X_train_q, X_test_q, y_train_q, y_test_q, qid_train_q, qid_test_q = train_test_split(X_q, y_q, qid_q, test_size=test_size, shuffle=True)\n",
    "\n",
    "        X_train.append(X_train_q)\n",
    "        X_test.append(X_test_q)\n",
    "        y_train.append(y_train_q)\n",
    "        y_test.append(y_test_q)\n",
    "        qid_train.append(qid_train_q)\n",
    "        qid_test.append(qid_test_q)\n",
    "\n",
    "    # Concatenate the results to get the final splits\n",
    "    X_train = np.concatenate(X_train)\n",
    "    X_test = np.concatenate(X_test)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    y_test = np.concatenate(y_test)\n",
    "    qid_train = np.concatenate(qid_train)\n",
    "    qid_test = np.concatenate(qid_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, qid_train, qid_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1\t1.0704006194194722\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "2\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "3\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "4\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "5\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "6\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "7\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "8\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "9\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "10\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "11\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "12\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "13\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "14\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "15\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "16\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "17\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "18\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "19\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "20\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n",
      "21\t0.8560085641270356\t2\t[1.         1.         0.36883632]\ttrain 0.7896\tvalid 0.7896\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaRank(estop=20, max_iter=100,\n",
       "        scorer=&lt;__main__.NDCGScorer object at 0x125277be0&gt;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaRank</label><div class=\"sk-toggleable__content\"><pre>AdaRank(estop=20, max_iter=100,\n",
       "        scorer=&lt;__main__.NDCGScorer object at 0x125277be0&gt;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaRank(estop=20, max_iter=100,\n",
       "        scorer=<__main__.NDCGScorer object at 0x125277be0>, verbose=True)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, qid_train, qid_test  = read_loinc()\n",
    "\n",
    "# hyper params\n",
    "k = 10\n",
    "max_iter = 100\n",
    "patience = 20\n",
    "\n",
    "model = AdaRank(max_iter=max_iter,\n",
    "                    estop=patience,\n",
    "                    verbose=True,\n",
    "                    scorer=NDCGScorer(k=k))\n",
    "\n",
    "model.fit(X, y, qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@1\t0.0\n",
      "nDCG@2\t0.0\n",
      "nDCG@3\t0.0\n",
      "nDCG@4\t0.1186132994310261\n",
      "nDCG@5\t0.15412787682487636\n",
      "nDCG@10\t0.29505782162709315\n",
      "nDCG@20\t0.29505782162709315\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, qid_test)\n",
    "for k in (1, 2, 3, 4, 5, 10, 20):\n",
    "        score = NDCGScorer(k=k)(y_test, predictions, qid_test).mean()\n",
    "        print('nDCG@{}\\t{}'.format(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LOINC extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1\t1.09386531354197\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "2\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "3\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "4\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "5\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "6\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "7\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "8\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "9\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "10\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "11\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "12\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "13\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "14\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "15\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "16\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "17\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "18\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "19\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "20\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n",
      "21\t0.8886608216911748\t2\t[1.         1.         0.39485376]\ttrain 0.7983\tvalid 0.7983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaRank(estop=20, max_iter=100,\n",
       "        scorer=&lt;__main__.NDCGScorer object at 0x12549dba0&gt;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaRank</label><div class=\"sk-toggleable__content\"><pre>AdaRank(estop=20, max_iter=100,\n",
       "        scorer=&lt;__main__.NDCGScorer object at 0x12549dba0&gt;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaRank(estop=20, max_iter=100,\n",
       "        scorer=<__main__.NDCGScorer object at 0x12549dba0>, verbose=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, qid_train, qid_test = read_loinc('datasets/loinc_extended_features.xlsx')\n",
    "\n",
    "# hyper params\n",
    "k = 10\n",
    "max_iter = 100\n",
    "patience = 20\n",
    "\n",
    "model = AdaRank(max_iter=max_iter,\n",
    "                    estop=patience,\n",
    "                    verbose=True,\n",
    "                    scorer=NDCGScorer(k=k))\n",
    "\n",
    "model.fit(X_train, y_train, qid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@1\t0.6666666666666666\n",
      "nDCG@2\t0.6666666666666666\n",
      "nDCG@3\t0.6145245859974715\n",
      "nDCG@4\t0.5672485934660606\n",
      "nDCG@5\t0.5748744139302352\n",
      "nDCG@10\t0.711748502626464\n",
      "nDCG@20\t0.8048251338886652\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, qid_test)\n",
    "for k in (1, 2, 3, 4, 5, 10, 20):\n",
    "        score = NDCGScorer(k=k)(y_test, predictions, qid_test).mean()\n",
    "        print('nDCG@{}\\t{}'.format(k, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
