{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score \n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.utils import check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaRank():\n",
    "    def __init__(self, k = 10, E = ndcg_score, n_iterations = 100):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.E = E\n",
    "        self.k = k\n",
    "        self.weights = None\n",
    "        self.weak_ranks = []\n",
    "        self.alphas = []\n",
    "        self.feature_scores = []\n",
    "        self.n_queries = None \n",
    "    \n",
    "    def fit(self, X, y, qid):\n",
    "        X = X.toarray()\n",
    "        dataset = []\n",
    "        \n",
    "        for q in np.unique(qid):\n",
    "            dataset.append((q, X[qid == q], y[qid == q]))\n",
    "        \n",
    "        self.n_queries = np.unique(qid).shape[0]\n",
    "        self.weights = np.ones(self.n_queries) /self.n_queries\n",
    "        \n",
    "        for j in range(X.shape[1]):\n",
    "            \n",
    "            feature_score = []\n",
    "            for data in dataset:\n",
    "                y_true = np.asarray([data[2]])\n",
    "                x_k = np.asarray([data[1][:, j]])\n",
    "                feature_score.append(self.E(y_true, x_k, k = self.k))\n",
    "            \n",
    "            self.feature_scores.append(feature_score)\n",
    "        \n",
    "        print(np.asarray(self.feature_scores).shape)\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            \n",
    "            # weak rank\n",
    "            best_feature = self.select_best_feature()\n",
    "            h_predictions = [] \n",
    "            x_best_feature = X[:, best_feature]\n",
    "            for q in np.unique(qid):\n",
    "                h_predictions.append(x_best_feature[qid == q])\n",
    "                \n",
    "            #h_predictions = dataset[:, 1, best_feature] # dataset[1] = X\n",
    "            print(np.asarray(h_predictions).shape)\n",
    "            self.weak_ranks.append(h_predictions)\n",
    "            \n",
    "            h_scores = []\n",
    "            for h_pred, data in zip(h_predictions, dataset):\n",
    "                y_true = np.asarray([data[2]])\n",
    "                h_scores.append(self.E(y_true, h_pred, k = self.k))\n",
    "            \n",
    "            print(f\"h_score: {np.asarray(h_scores).shape}\")\n",
    "            \n",
    "            # h score shape deve (1017,)\n",
    "            # Choose alpha t\n",
    "            alpha = 0.5 * np.log((self.weights * (1 + h_scores)) / (1 - h_scores))\n",
    "            # ALPHA E' un numero\n",
    "            \n",
    "            self.alphas.append(alpha)\n",
    "            \n",
    "            f_predictions = np.sum(self.alphas * self.weak_ranks, axis = 0)\n",
    "            \n",
    "            # update P t+1\n",
    "            f_score = self.E(y, f_predictions, k = self.k)\n",
    "            self.weights = np.exp(-f_score) / np.exp(np.sum(-f_score))\n",
    "    \n",
    "    def select_best_feature(self):\n",
    "        \"\"\"Create weak ranker ht with weighted distribution Pt on training data\"\"\"\n",
    "        \n",
    "        best_feature = None\n",
    "        best_weighted_performance = -np.inf\n",
    "        \n",
    "        for fid, score in enumerate(self.feature_scores):\n",
    "            \n",
    "            weighted_average = np.dot(self.weights, score)\n",
    "            \n",
    "            if weighted_average > best_weighted_performance:\n",
    "                best_feature = fid\n",
    "                best_weighted_performance = weighted_average\n",
    "\n",
    "        # Return the best feature\n",
    "        return best_feature\n",
    "        \n",
    "                \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "K = 10\n",
    "max_iter = 100\n",
    "estop = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, qid = load_svmlight_file(\"datasets/mq2007/train.txt\", query_id=True)\n",
    "    \n",
    "X_test, y_test, qid_test = load_svmlight_file(\"datasets/mq2007/test.txt\", query_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (42158, 46), y: (42158,), qid: (42158,)\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print(f\"X: {X.shape}, y: {y.shape}, qid: {qid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for q in np.unique(qid):\n",
    "    dataset.append((q, X[qid == q], y[qid == q]))\n",
    "    # dataset.append({    \n",
    "    #     \"qid\": q,\n",
    "    #     \"X\": X[qid == q],\n",
    "    #     \"y\": y[qid == q]         \n",
    "    #                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 1017)\n",
      "(1017,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/wf0bbt912gb82tgxbnlz82bm0000gn/T/ipykernel_95054/4070105830.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(np.asarray(h_predictions).shape)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 40]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m AdaRank(k \u001b[39m=\u001b[39m K, E \u001b[39m=\u001b[39m E, n_iterations \u001b[39m=\u001b[39m n_iterations) \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y, qid)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m):\n",
      "\u001b[1;32m/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mfor\u001b[39;00m h_pred, data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(h_predictions, dataset):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([data[\u001b[39m2\u001b[39m]])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     h_scores\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mE(y_true, h_pred, k \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mh_score: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39masarray(h_scores)\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# h score shape deve (1017,)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzoleuzzi/Documents/GitHub/BioInformatics-AdaRank/adarank.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Choose alpha t\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1638\u001b[0m, in \u001b[0;36mndcg_score\u001b[0;34m(y_true, y_score, k, sample_weight, ignore_ties)\u001b[0m\n\u001b[1;32m   1636\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1637\u001b[0m y_score \u001b[39m=\u001b[39m check_array(y_score, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1638\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m   1639\u001b[0m _check_dcg_target_type(y_true)\n\u001b[1;32m   1640\u001b[0m gain \u001b[39m=\u001b[39m _ndcg_sample_scores(y_true, y_score, k\u001b[39m=\u001b[39mk, ignore_ties\u001b[39m=\u001b[39mignore_ties)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 40]"
     ]
    }
   ],
   "source": [
    "model = AdaRank()\n",
    "\n",
    "model.fit(X, y, qid)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "for k in (1, 2, 3, 4, 5, 10, 20):\n",
    "        score = ndcg_score(y_test, predictions, k = k).mean()\n",
    "        print('nDCG@{}\\t{}'.format(k, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
